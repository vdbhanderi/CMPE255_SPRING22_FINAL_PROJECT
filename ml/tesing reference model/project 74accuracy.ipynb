{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NEWAoUNP8xH",
        "outputId": "a878ec55-b7f6-4cf7-ee95-5261be95942d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import re\n",
        "import os\n",
        "tf.__version__\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CLrsbOIpTU1m"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv(\"/content/drive/MyDrive/Colab_Notebooks/train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/Colab_Notebooks/val.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s5oWgBqmTp7p"
      },
      "outputs": [],
      "source": [
        "# def clean_data(text):\n",
        "#     text = text.lower()\n",
        "#     text = re.sub(r\"[-=+*\\\"#@!$%^&()`<>\\[\\]]\",\"\",text)\n",
        "#     text = re.sub(r\"i'm\",\"i am\",text)\n",
        "#     text = re.sub(r\"he's\",\"he is\",text)\n",
        "#     text = re.sub(r\"she's\",\"she is\",text)\n",
        "#     text = re.sub(r\"it's\",\"it is\",text)\n",
        "#     text = re.sub(r\"they're\",\"they are\",text)\n",
        "#     text = re.sub(r\"there're\",\"there are\",text)\n",
        "#     text = re.sub(r\"there's\",\"there is\",text)\n",
        "#     text = re.sub(r\"how're\",\"how are\",text)\n",
        "#     text = re.sub(r\"what're\",\"what are\",text)\n",
        "#     text = re.sub(r\"where're\",\"where \",text)\n",
        "#     text = re.sub(r\"who're\",\"who are\",text)\n",
        "#     text = re.sub(r\"that're\",\"that are\",text)\n",
        "#     text = re.sub(r\"when're\",\"when are\",text)\n",
        "#     text = re.sub(r\"how's\",\"how is\",text)\n",
        "#     text = re.sub(r\"what's\",\"what is\",text)\n",
        "#     text = re.sub(r\"where's\",\"where is\",text)\n",
        "#     text = re.sub(r\"who's\",\"who is\",text)\n",
        "#     text = re.sub(r\"that's\",\"that is\",text)\n",
        "#     text = re.sub(r\"when's\",\"when is\",text)\n",
        "#     text = re.sub(r\"won't\",\"would not\",text)\n",
        "#     text = re.sub(r\"nt't\",\"can not\",text)\n",
        "#     text = re.sub(r\"\\'bout'\",\"about\",text)\n",
        "#     text = re.sub(r\"\\'till'\",\"untill\",text)\n",
        "#     text = re.sub(r\"\\'ll\",\"will\",text)\n",
        "#     text = re.sub(r\"\\'ve\",\"have\",text)\n",
        "#     text = re.sub(r\"\\'re\",\"are\",text)\n",
        "#     text = re.sub(r\"\\'d\",\"would\",text)\n",
        "#     text = re.sub(r\"\\.\",\" \",text)\n",
        "#     text = re.sub(r\"\\,\",\" \",text)\n",
        "#     text = re.sub(r\"\\!\",\" \",text)\n",
        "#     text = re.sub(r\"\\?\",\" \",text)\n",
        "#     text = re.sub(r\"\\;\",\" \",text)\n",
        "#     text = re.sub(r\"\\:\",\" \",text)\n",
        "#     return text\n",
        "\n",
        "    \n",
        "# df['text'] = df['text'].apply(clean_data)\n",
        "# df['augmented_text'] = df['augmented_text'].apply(clean_data)\n",
        "# df_val['text'] = df['text'].apply(clean_data)\n",
        "# df_val['augmented_text'] = df['augmented_text'].apply(clean_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X4xURgshSrpT"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/Copy of data.csv')\n",
        "# df = df[:82000]\n",
        "train_df = df['augmented_text']\n",
        "test_df = df['text']\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_x, test_x, train_y, test_y = train_test_split(train_df, test_df, test_size=0.5, random_state=24)\n",
        "val_x, test_x,val_y, test_y = train_test_split(test_x, test_y, test_size = 0.8, random_state=24)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZMTBLH1H-U7",
        "outputId": "2db39af6-fb6f-469a-ecd3-859275589297"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "665124    amerkdan citizen who xiev in darwin prison mus...\n",
              "614705                      ddney fc nwcastle jets a league\n",
              "725648    politicinsa with unfortunate nicknames that sitkc\n",
              "62804     ejff horn trainer eglnn rushton deefdns action...\n",
              "458699            mandatory glucose testing teyp 1 dibaeets\n",
              "                                ...                        \n",
              "478609           local govt trojp backs highway revxm9 gnds\n",
              "516439    png rcciket manager says team has let two gold...\n",
              "211136           fitrzyo water plan  poropsal to open awtre\n",
              "899                efth city bxnq smoking in pedestrian aas\n",
              "242082           bowierc can be hero3z at the icc wirls cup\n",
              "Name: augmented_text, Length: 461184, dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inUltHgQ191H",
        "outputId": "480b99bb-e531-44de-a75b-b32dce9e0d25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "401835    wxunh in rughing for australian of the year xwqrd\n",
              "889764       daeladie zoo apndsa emekrats get easter treats\n",
              "376080    iaea offers to guarantee ifahs nucpea fhe  supply\n",
              "860972    heated debate vore call for fouhrt warrnambool...\n",
              "260601    cricket mtahc interrupted by rcossobw btol on ...\n",
              "                                ...                        \n",
              "419844            hivt sets stolen gendgations apology date\n",
              "741935    rmma hcar eyects latest allegations of misconduct\n",
              "238252      acremn brown speaks to tony gifrfiths boaut the\n",
              "912800        uq vice chancellor brigrs eodward resignation\n",
              "454594                briedg collapse in genoa kills dozens\n",
              "Name: augmented_text, Length: 92237, dtype: object"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gcvdQ8ox3lpP"
      },
      "outputs": [],
      "source": [
        "max_length = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sTa8D0WfT1gf"
      },
      "outputs": [],
      "source": [
        "\n",
        "g_text_tokenizer = Tokenizer()\n",
        "g_text_tokenizer.fit_on_texts(train_x)\n",
        "g_text_word_index = g_text_tokenizer.word_index\n",
        "train_sequences = g_text_tokenizer.texts_to_sequences(train_x)\n",
        "train_padded = pad_sequences(train_sequences, maxlen = max_length, padding='post')\n",
        "\n",
        "\n",
        "text_tokenizer = Tokenizer()\n",
        "text_tokenizer.fit_on_texts(train_y)\n",
        "text_word_index = text_tokenizer.word_index\n",
        "test_sequences = text_tokenizer.texts_to_sequences(train_y)\n",
        "test_padded = pad_sequences(test_sequences,maxlen = max_length, padding='post')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4PWLtCPyLNVJ"
      },
      "outputs": [],
      "source": [
        "val_train_sequences = g_text_tokenizer.texts_to_sequences(val_x)\n",
        "val_train_padded = pad_sequences(val_train_sequences, maxlen = max_length, padding='post')\n",
        "\n",
        "val_test_sequences = text_tokenizer.texts_to_sequences(val_y)\n",
        "val_test_padded = pad_sequences(val_test_sequences, maxlen = max_length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npA5T2pATdEK",
        "outputId": "4072f70d-3302-4327-e410-cadc9f2e58ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "688249 74657\n"
          ]
        }
      ],
      "source": [
        "g_vocab_size = len(g_text_word_index)+1\n",
        "vocab_size = len(text_word_index)+1\n",
        "print(g_vocab_size, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_XpYdlglhS4Z"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=g_vocab_size, output_dim=1028, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(vocab_size,activation='softmax')\n",
        "])\n",
        "learning_rate = 0.01\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate)\n",
        "optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIDyD7DqT-_c",
        "outputId": "286dcde0-7fce-4fb5-a6c4-9514e2088128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "____________________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   Trainable  \n",
            "============================================================================\n",
            " embedding (Embedding)       (None, 8, 1028)           70751997  Y          \n",
            "                                                       2                    \n",
            "                                                                            \n",
            " bidirectional (Bidirectiona  (None, 8, 512)           2631680   Y          \n",
            " l)                                                                         \n",
            "                                                                            \n",
            " dropout (Dropout)           (None, 8, 512)            0         Y          \n",
            "                                                                            \n",
            " bidirectional_1 (Bidirectio  (None, 8, 512)           1574912   Y          \n",
            " nal)                                                                       \n",
            "                                                                            \n",
            " dropout_1 (Dropout)         (None, 8, 512)            0         Y          \n",
            "                                                                            \n",
            " bidirectional_2 (Bidirectio  (None, 8, 512)           1574912   Y          \n",
            " nal)                                                                       \n",
            "                                                                            \n",
            " dropout_2 (Dropout)         (None, 8, 512)            0         Y          \n",
            "                                                                            \n",
            " dense (Dense)               (None, 8, 74657)          38299041  Y          \n",
            "                                                                            \n",
            "============================================================================\n",
            "Total params: 751,600,517\n",
            "Trainable params: 751,600,517\n",
            "Non-trainable params: 0\n",
            "____________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary(expand_nested=True,\n",
        "    show_trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuTZ37PK2-mh",
        "outputId": "09049ed2-3dc6-4403-9369-c4b86d31d811"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(461184, 8)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_padded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eVK8H4m5dqdD"
      },
      "outputs": [],
      "source": [
        "temp_test_padded = test_padded.reshape((test_padded.shape[0], test_padded.shape[1],1))\n",
        "temp_train_padded = train_padded.reshape((train_padded.shape[0], train_padded.shape[1],1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz1009MuUGX-",
        "outputId": "0ac9b6bf-1e0f-4576-a173-034157494639"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:439: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 707519972 elements. This may consume a large amount of memory.\n",
            "  num_elements)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "901/901 [==============================] - 458s 498ms/step - loss: 4.6550 - accuracy: 0.4218 - val_loss: 10.3255 - val_accuracy: 0.4613\n",
            "Epoch 2/20\n",
            "901/901 [==============================] - 447s 496ms/step - loss: 3.4067 - accuracy: 0.5595 - val_loss: 12.9525 - val_accuracy: 0.4996\n",
            "Epoch 3/20\n",
            "901/901 [==============================] - 447s 496ms/step - loss: 3.0202 - accuracy: 0.5962 - val_loss: 15.2032 - val_accuracy: 0.5180\n",
            "Epoch 4/20\n",
            "901/901 [==============================] - 447s 496ms/step - loss: 2.7695 - accuracy: 0.6200 - val_loss: 17.2753 - val_accuracy: 0.5298\n",
            "Epoch 5/20\n",
            "901/901 [==============================] - 447s 496ms/step - loss: 2.5773 - accuracy: 0.6383 - val_loss: 17.0032 - val_accuracy: 0.5375\n",
            "Epoch 6/20\n",
            "901/901 [==============================] - 447s 496ms/step - loss: 2.4295 - accuracy: 0.6539 - val_loss: 18.9542 - val_accuracy: 0.5434\n",
            "Epoch 7/20\n",
            "901/901 [==============================] - 446s 496ms/step - loss: 2.3106 - accuracy: 0.6677 - val_loss: 19.2280 - val_accuracy: 0.5491\n",
            "Epoch 8/20\n",
            "901/901 [==============================] - 446s 496ms/step - loss: 2.2175 - accuracy: 0.6797 - val_loss: 19.4868 - val_accuracy: 0.5530\n",
            "Epoch 9/20\n",
            "901/901 [==============================] - 447s 496ms/step - loss: 2.1430 - accuracy: 0.6899 - val_loss: 20.1849 - val_accuracy: 0.5555\n",
            "Epoch 10/20\n",
            "901/901 [==============================] - 447s 496ms/step - loss: 2.0829 - accuracy: 0.6988 - val_loss: 20.9156 - val_accuracy: 0.5586\n",
            "Epoch 11/20\n",
            "901/901 [==============================] - 447s 496ms/step - loss: 2.0366 - accuracy: 0.7063 - val_loss: 21.2848 - val_accuracy: 0.5606\n",
            "Epoch 12/20\n",
            "901/901 [==============================] - 447s 496ms/step - loss: 1.9975 - accuracy: 0.7131 - val_loss: 21.8057 - val_accuracy: 0.5628\n",
            "Epoch 13/20\n",
            "901/901 [==============================] - 447s 496ms/step - loss: 1.9666 - accuracy: 0.7186 - val_loss: 23.1994 - val_accuracy: 0.5652\n",
            "Epoch 14/20\n",
            "901/901 [==============================] - 447s 496ms/step - loss: 1.9444 - accuracy: 0.7234 - val_loss: 22.5046 - val_accuracy: 0.5661\n",
            "Epoch 15/20\n",
            "901/901 [==============================] - 447s 497ms/step - loss: 1.9218 - accuracy: 0.7279 - val_loss: 23.5779 - val_accuracy: 0.5681\n",
            "Epoch 16/20\n",
            "901/901 [==============================] - 448s 497ms/step - loss: 1.9087 - accuracy: 0.7314 - val_loss: 21.2886 - val_accuracy: 0.5680\n",
            "Epoch 17/20\n",
            "901/901 [==============================] - 448s 497ms/step - loss: 1.8970 - accuracy: 0.7345 - val_loss: 25.8915 - val_accuracy: 0.5700\n",
            "Epoch 18/20\n",
            "901/901 [==============================] - 448s 497ms/step - loss: 1.8841 - accuracy: 0.7377 - val_loss: 26.5513 - val_accuracy: 0.5707\n",
            "Epoch 19/20\n",
            "901/901 [==============================] - 448s 497ms/step - loss: 1.8758 - accuracy: 0.7407 - val_loss: 26.1767 - val_accuracy: 0.5717\n",
            "Epoch 20/20\n",
            "901/901 [==============================] - 448s 497ms/step - loss: 1.8709 - accuracy: 0.7430 - val_loss: 26.0687 - val_accuracy: 0.5724\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd748e102d0>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epoch = 20\n",
        "model.fit(train_padded, test_padded, batch_size=512, epochs=epoch, validation_data = (val_train_padded, val_test_padded))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8sU_NqNEcC1"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADAyQCdl7mmw",
        "outputId": "ce723b73-1aa0-4ab9-ca90-79fccda0421d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab_Notebooks/20_epoch_accuracy_93_3bidirectional_lstm_rnn_15inputlength/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab_Notebooks/20_epoch_accuracy_93_3bidirectional_lstm_rnn_15inputlength/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fd7dd47ec90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fd7dd406a90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fd7d013bc10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fd7d0144a50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fd7d0150bd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fd7d015aad0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/Colab_Notebooks/20_epoch_accuracy_93_3bidirectional_lstm_rnn_15inputlength')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KpGWAIiQUe0_"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_sample = test_x.iloc[:2]\n",
        "test_sample = g_text_tokenizer.texts_to_sequences(test_sample)\n",
        "test_sample = pad_sequences(test_sample, maxlen=max_length, padding='post')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phthuwn2sMov",
        "outputId": "6bd59aaa-9283-42b3-9a7a-a51dd1f0069d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 8)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_sample.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUHeCyCM02he",
        "outputId": "4ee74af9-83c4-4129-caf7-02fc0df75b2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "492910    polglase jnfaz3d by inquiry levql implications\n",
              "491467              ruthless bajrn expose arqenzls flaws\n",
              "Name: augmented_text, dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_x.iloc[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o48mfKmhsDv0",
        "outputId": "6d1e391c-0fc0-4e5e-928d-1728594aad74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "492910    polglase unfazed by inquiry legal implications\n",
              "491467             ruthless bayern expose arsenals flaws\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_y.iloc[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvPsR8hHEQq9",
        "outputId": "4c6b5e3c-9b44-441a-fa13-0aaef6d0ab73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 8, 74657)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pre = model.predict(test_sample)\n",
        "pre.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCXcto7u1iTa",
        "outputId": "74bd691d-6478-4ca0-f7fc-a48cb6523a40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([  43,   20,  148,  370, 8886,    0,    0,    0])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.argmax(pre[0],1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IGZ5AzDTcDHa"
      },
      "outputs": [],
      "source": [
        "def deTokenize(logits):\n",
        "    index_to_words = {id: word for word, id in text_tokenizer.word_index.items()}\n",
        "    index_to_words[0] = ''\n",
        "    pre_index = np.argmax(logits, 1)\n",
        "    return ' '.join(index_to_words[prediction] for prediction in pre_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za9Vd_dEED-H",
        "outputId": "74748070-3849-4999-de37-16df1ae8e7d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iutput:     polglase jnfaz3d by inquiry levql implications\n",
            "Actual:     polglase unfazed by inquiry legal implications\n",
            "Predicted:  charged by inquiry legal incursion   \n"
          ]
        }
      ],
      "source": [
        "print(\"Iutput:    \",test_x.iloc[0])\n",
        "print(\"Actual:    \",test_y.iloc[0])\n",
        "print(\"Predicted: \",deTokenize(pre[0]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
