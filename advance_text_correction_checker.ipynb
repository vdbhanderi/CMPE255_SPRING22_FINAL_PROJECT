{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import re\n",
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "import tensorflow as tf\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "# tf.test.is_gpu_available(\n",
    "#     cuda_only=False, min_cuda_compute_capability=None\n",
    "# )\n",
    "# gpu = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(gpu[0],True)\n",
    "\n",
    "# print(tf.config.list_physical_devices('GPU'))\n",
    "# tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv('train.csv')\n",
    "# df_val = pd.read_csv(\"val.csv\")\n",
    "# text_data = pd.concat([df_train,df_val])\n",
    "# text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Cleaning and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = pd.read_csv(\"val.csv\")\n",
    "\n",
    "def clean_data(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[-=+*\\\"#@!$%^&()`<>\\[\\]]\",\"\",text)\n",
    "    text = re.sub(r\"i'm\",\"i am\",text)\n",
    "    text = re.sub(r\"he's\",\"he is\",text)\n",
    "    text = re.sub(r\"she's\",\"she is\",text)\n",
    "    text = re.sub(r\"it's\",\"it is\",text)\n",
    "    text = re.sub(r\"they're\",\"they are\",text)\n",
    "    text = re.sub(r\"there're\",\"there are\",text)\n",
    "    text = re.sub(r\"there's\",\"there is\",text)\n",
    "    text = re.sub(r\"how're\",\"how are\",text)\n",
    "    text = re.sub(r\"what're\",\"what are\",text)\n",
    "    text = re.sub(r\"where're\",\"where \",text)\n",
    "    text = re.sub(r\"who're\",\"who are\",text)\n",
    "    text = re.sub(r\"that're\",\"that are\",text)\n",
    "    text = re.sub(r\"when're\",\"when are\",text)\n",
    "    text = re.sub(r\"how's\",\"how is\",text)\n",
    "    text = re.sub(r\"what's\",\"what is\",text)\n",
    "    text = re.sub(r\"where's\",\"where is\",text)\n",
    "    text = re.sub(r\"who's\",\"who is\",text)\n",
    "    text = re.sub(r\"that's\",\"that is\",text)\n",
    "    text = re.sub(r\"when's\",\"when is\",text)\n",
    "    text = re.sub(r\"won't\",\"would not\",text)\n",
    "    text = re.sub(r\"nt't\",\"can not\",text)\n",
    "    text = re.sub(r\"\\'bout'\",\"about\",text)\n",
    "    text = re.sub(r\"\\'till'\",\"untill\",text)\n",
    "    text = re.sub(r\"\\'ll\",\"will\",text)\n",
    "    text = re.sub(r\"\\'ve\",\"have\",text)\n",
    "    text = re.sub(r\"\\'re\",\"are\",text)\n",
    "    text = re.sub(r\"\\'d\",\"would\",text)\n",
    "    text = re.sub(r\"\\.\",\" \",text)\n",
    "    text = re.sub(r\"\\,\",\" \",text)\n",
    "    text = re.sub(r\"\\!\",\" \",text)\n",
    "    text = re.sub(r\"\\?\",\" \",text)\n",
    "    text = re.sub(r\"\\;\",\" \",text)\n",
    "    text = re.sub(r\"\\:\",\" \",text)\n",
    "    return text\n",
    "\n",
    "    \n",
    "text_data['text'] = text_data['text'].apply(clean_data)\n",
    "text_data['augmented_text'] = text_data['augmented_text'].apply(clean_data)\n",
    "\n",
    "# # text_data.to_csv('data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 10\n",
    "\n",
    "text_tokenizer = Tokenizer()\n",
    "text_tokenizer.fit_on_texts(text_data['text'])\n",
    "text_word_index = text_tokenizer.word_index\n",
    "test_sequences = text_tokenizer.texts_to_sequences(text_data['text'])\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post',truncating='post')\n",
    "\n",
    "g_text_tokenizer = Tokenizer()\n",
    "g_text_tokenizer.fit_on_texts(text_data['augmented_text'])\n",
    "g_text_word_index = g_text_tokenizer.word_index\n",
    "train_sequences = g_text_tokenizer.texts_to_sequences(text_data['augmented_text'])\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post',truncating='post')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g_vocab_size = len(g_text_word_index)+1\n",
    "vocab_size = len(text_word_index)+1\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True), input_shape=(10,1)),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(64, activation='relu')),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_size,activation='softmax'))\n",
    "])\n",
    "# learning_rate = 2\n",
    "optimizer = tf.keras.optimizers.RMSprop()\n",
    "optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 10, 64)           8704      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 10, 64)           4160      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10, 64)            0         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 10, 47127)        3063255   \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,076,119\n",
      "Trainable params: 3,076,119\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153728, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do just change the epoch to 10, 20, 50, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "301/301 [==============================] - 1054s 3s/step - loss: 5.9859 - accuracy: 0.3034\n",
      "Epoch 2/5\n",
      "301/301 [==============================] - 1049s 3s/step - loss: 5.2281 - accuracy: 0.3504\n",
      "Epoch 3/5\n",
      "301/301 [==============================] - 1049s 3s/step - loss: 5.0809 - accuracy: 0.3708\n",
      "Epoch 4/5\n",
      "301/301 [==============================] - 1050s 3s/step - loss: 4.9808 - accuracy: 0.3789\n",
      "Epoch 5/5\n",
      "301/301 [==============================] - 1048s 3s/step - loss: 4.9049 - accuracy: 0.3839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201dbf040a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = \n",
    "temp_test_padded = test_padded.reshape(test_padded.shape[0], test_padded.shape[1],1)\n",
    "# train_padded = train_padded.reshape(train_padded.shape[0], train_padded.shape[1], 1)\n",
    "\n",
    "model.fit(train_padded, temp_test_padded, epochs=epoch,verbose=1,batch_size=512)\n",
    "\n",
    "# try:\n",
    "#     with tf.device(gpu[0]):\n",
    "# except RuntimeError as e:\n",
    "#       print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5_epoch_accuracy_0.3839_bidirectional_lstm_rnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5_epoch_accuracy_0.3839_bidirectional_lstm_rnn\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000201DAD4AF10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000201DAE18A30> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "model.save('5_epoch_accuracy_0.3839_bidirectional_lstm_rnn')\n",
    "#load model\n",
    "n_m= tf.keras.models.load_model('5_epoch_accuracy_0.3839_bidirectional_lstm_rnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0962007208e8a212392648a14fd1c44261e754d037764989b21077e2a05bb5f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
